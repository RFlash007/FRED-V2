F.R.E.D. Cognitive Architecture Overhaul: Complete Blueprint
Objective: To evolve F.R.E.D. from an agent with a knowledge graph into a sophisticated cognitive architecture with a multi-layered, human-like memory system. This document provides a complete, detailed plan for implementation.

Section 1: Core Architectural Principles
The system's cognitive functions will be managed by two distinct, interacting agents, orchestrated by a programmatic wrapper.

F.R.E.D. (The Conversational Agent): The primary, user-facing LLM. Its core duties are to understand immediate user intent, maintain a consistent and engaging personality, and act upon the final, curated context provided to it by CRAP.

CRAP (Context Retrieval for Augmented Prompts): F.R.E.D.'s dedicated memory and cognition engine.

The CRAP LLM: A powerful model (e.g., Qwen3-30B) that performs the core analysis, reasoning, and tool-use decisions related to memory.

The CRAP Code Wrapper (crap.py): The programmatic orchestrator. It manages data flows, executes tool calls based on the LLM's decisions, handles background tasks, and assembles the final prompts for both the CRAP LLM and F.R.E.D.

Section 2: The Three-Layer Memory Hierarchy & Schemas
L1: Working Memory (The "Now")
Implementation: Managed by CRAP's code as an in-memory deque, representing the active conversation history passed into the context window.

Context Window Strategy:

Turns 1-3 (Immediate Context): Retain the full context: user message, F.R.E.D.'s internal "thinking" monologue, and F.R.E.D.'s final response.

Turns 4-25 (Recent Context): Strip the "thinking" monologue. Retain only the final User: and F.R.E.D.: messages.

Turns 25+ (Archived Context): Messages are dropped entirely from the L1 active context window.

L2: Episodic Cache (The "Recent Past")
Implementation: A dedicated "Rolling RAG Database" (e.g., a DuckDB instance with a vector index).

**This is replacing current short term memory implementation**

Trigger for Creation (Managed by CRAP's code):

Semantic Trigger: On each turn, CRAP's code calculates the vector embedding of the latest user message. It compares this embedding (using cosine similarity) to a rolling average embedding of the last 5-7 turns. If the similarity score drops below a pre-set threshold (e.g., 0.6), it signals a topic change and triggers the creation of an L2 summary for the preceding chunk.

Fallback Trigger: If a single conversational topic exceeds a hardcoded limit (e.g., 15 turns), an L2 memory is created automatically.

Lifecycle: L2 summaries reside in this database for 14 days, identified by their created_at timestamp. After this period, they become eligible for L3 consolidation.

L2 Database Schema: See Section 7.

L3: Permanent Knowledge Graph (The "Consolidated Past")
Implementation: The existing librarian.py DuckDB knowledge graph.

Node Schemas: See Section 7.

Procedural Node Creation: A Procedural node is created when the CRAP LLM identifies a repeatable, multi-step task within a conversation. CRAP calls its add_memory tool to create the Procedural node.

Section 3: The Memory Pipeline (A Single Interaction)
Prompt Arrival: User sends a message.

Pre-computation (CRAP's Code): The code automatically generates an embedding for the user's message and queries the L2 Rolling RAG Database. The top N relevant L2 summaries are retrieved.

CRAP LLM Analysis: CRAP's code assembles a prompt for the CRAP LLM containing the user's message, the L1 working memory, and the retrieved L2 summaries. The CRAP LLM then analyzes this context and decides which of its tools to call. This is the stage where it performs:

Real-time Entity Extraction by calling add_memory(fact).

L3 Knowledge Retrieval by calling search_memory(query).

Memory Correction by calling supersede_memory(old_node_id, new_fact).

External Research by calling search_web_information(query).

Context Assembly (CRAP's Code): After the CRAP LLM completes its tool calls, it generates a final, structured "FRED DATABASE" output. CRAP's code injects this output into F.R.E.D.'s prompt.

Response (F.R.E.D.): F.R.E.D. receives the augmented prompt and formulates its response.

L2 Creation (CRAP's Code): Independently, CRAP's code runs its trigger checks and, if met, generates and stores a new L2 summary in the Rolling RAG Database.

Section 4: Proactive Learning (The Agenda)
Implementation: A dedicated table named The Agenda.

Schema: See Section 7.

F.R.E.D.'s Role: F.R.E.D. has the addTaskToAgenda tool to capture user requests for future research.

Execution Flow (During Sleep Cycle):

Problem Decomposition: For each task, CRAP's code calls a "Thinker" LLM. The Thinker's job is to break the complex task into a JSON array of specific, researchable questions.

Information Gathering: CRAP's code loops through this array, feeding each question to a "Researcher" model. The Researcher's sole job is to execute the search_web_information tool and return a factual snippet.

Synthesis: The Thinker model receives all the factual snippets and synthesizes them into a coherent answer.

Memorization: CRAP's code takes this final answer and uses add_memory to create a new node in the L3 Knowledge Graph. The Agenda task is marked as complete, and a notification is queued.

Section 5: The Sleep Cycle (Offline Consolidation)
Trigger: F.R.E.D. calls the triggerSleepCycle() tool.

Execution Flow:

CRAP's Code Intercepts: The tool call is intercepted. The user is given an immediate acknowledgement ("Okay, initiating sleep cycle...").

Offline Tasks Begin: CRAP's code executes the full sequence of offline tasks: Process The Agenda, process pending graph edges, run L3 consolidation (querying L2 for items >14 days old), and run memory pruning.

Summary Generation: Once all tasks are complete, CRAP's code generates a brief summary of the work done.

Wake-Up Priming: This summary is handed to the CRAP LLM so he can go ahead and augment FREDS next prompt with this summary

Wake-Up Delivery: On the user's next interaction, CRAP's code retrieves this summary and passes it as special context to the CRAP LLM, which then formulates the natural language "waking up" message for F.R.E.D. to deliver.

Section 6: The Notification Queue
Purpose: To bridge offline task completion with the user's real-time conversation, enabling proactive updates.

Implementation: A dedicated table in the database.

Schema: See Section 7.

Lifecycle:

Creation: When an Agenda task is completed during the Sleep Cycle, CRAP's code creates a new pending notification.

Checking: At the start of a new user session, CRAP's code checks for any pending notifications for that user.

Delivery: The pending notifications are passed to the CRAP LLM, which formulates the natural language update for F.R.E.D. to deliver.

Updating: Once passed to the LLM, CRAP's code immediately updates the notification's status to delivered to prevent duplicate alerts.

Section 7: Schemas and Prompting Strategies
Database Schemas
L2 Database Schema (per document):

{
  "l2_id": "l2_uuid_12345", "conversation_id": "conv_abcde", "created_at": "timestamp", "turn_start": 26, "turn_end": 40, "embedding": "[...]",
  "content": { "topic": "...", "key_outcomes": ["..."], "entities_mentioned": ["..."], "user_sentiment": "...", "raw_text_summary": "..." }
}


L3 Node Schemas:

**Use Episodic, Procedural, and Semantic which is already implemented**

The Agenda Task Schema:

{
  "task_id": "agenda_uuid_123", "status": "pending", "type": "user_request", "priority": 2, "content": "Investigate pricing trends for...", "source_conversation_id": "conv_abcde", "created_at": "timestamp", "result_node_id": null
}


Notification Queue Schema:

{
  "notification_id": "notif_uuid_789", "user_id": "user_xyz", "status": "pending", "created_at": "timestamp", "source_task_id": "agenda_uuid_123", "message_summary": "Completed research on...", "related_node_id": "sem_uuid_abc"
}


Core Prompting Strategies
F.R.E.D.'s Meta-Cognition Prompt:

"Before answering, analyze the user's query. Is it about a timeless fact you know, or a recent/developing event? If it requires recent data you don't possess, and the user wants it done later, use the addTaskToAgenda tool. Otherwise, rely on the context provided by CRAP."

CRAP's Memory Correction Prompt:

"Review the conversation for explicit user corrections (e.g., 'No, that's wrong...', 'Actually, it's...'). If a user statement directly contradicts a fact retrieved from the L3 knowledge graph, you MUST call the supersede_memory tool with the ID of the old node and the corrected information."

Section 8: Tooling Summary
F.R.E.D.'s Tools: addTaskToAgenda(task_description: str, priority: int), triggerSleepCycle().

CRAP's Tools: search_memory, add_memory, supersede_memory, get_node_by_id, get_graph_data, update_knowledge_graph_edges, search_web_information.