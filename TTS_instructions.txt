Instructions for `clone_and_speak.py` (Local Text-to-Speech with Voice Cloning)

**Purpose:**
The `clone_and_speak.py` script is designed to:
1. Use Coqui TTS (specifically the Idiap community-maintained fork) to clone a voice from a `.wav` audio file you provide.
2. Take a predefined text input from within the script.
3. Convert that text to speech using the cloned voice.
4. Save the generated speech to an audio file named `cloned_speech.wav`.
5. Automatically play the `cloned_speech.wav` file using your system's default audio player.

**Prerequisites:**
1.  **Install Coqui TTS:**
    *   Open your terminal or command prompt.
    *   Run the command: `pip install coqui-tts`
    *   This installs the Idiap fork, which is recommended for active maintenance.

**Setup Before Running `clone_and_speak.py`:**

1.  **Prepare Your Voice Sample:**
    *   You need a `.wav` audio file of the voice you wish to clone.
    *   The audio should be clear. A few seconds (e.g., 5-15 seconds) of continuous speech is generally good.
    *   Save this `.wav` file. For ease of use, you can place it in the same directory as the `clone_and_speak.py` script (your workspace root).

2.  **Update `SPEAKER_WAV_PATH` in `clone_and_speak.py`:**
    *   Open the `clone_and_speak.py` script.
    *   Locate the line: `SPEAKER_WAV_PATH = "path/to/your/voice_sample.wav"`
    *   Modify the path string to point to your actual `.wav` file.
        *   Example: If your file is named `my_voice_sample.wav` and is in the same directory as the script, change the line to: `SPEAKER_WAV_PATH = "my_voice_sample.wav"`

3.  **Customize `TEXT_TO_SPEAK` (Optional):**
    *   In `clone_and_speak.py`, you can change the text that will be synthesized by modifying the `TEXT_TO_SPEAK` variable.
    *   `TEXT_TO_SPEAK = "Your desired text here."`

**How to Run the Script:**

1.  Open your terminal or command prompt.
2.  Navigate to the directory where `clone_and_speak.py` is located (your F.R.E.D.-V2 workspace root).
3.  Execute the script using the command: `python clone_and_speak.py`

**Expected Behavior:**

*   **Model Download (First Run):** The first time you execute the script, Coqui TTS will download the specified voice cloning model (e.g., `tts_models/multilingual/multi-dataset/xtts_v2`). This may take some time, depending on your internet speed.
*   **Device Selection:** The script will print whether it's using a "cuda" (NVIDIA GPU) or "cpu" device.
*   **Voice Cloning & TTS:** It will process your `SPEAKER_WAV_PATH` to clone the voice and then convert `TEXT_TO_SPEAK` into speech using this cloned voice.
*   **Output File:** The synthesized audio will be saved as `cloned_speech.wav` in the same directory as the script.
*   **Automatic Playback:** The script will attempt to play `cloned_speech.wav` using your system's default audio player.

**Important Considerations & Troubleshooting:**

*   **Hardware Resources:**
    *   **GPU (Highly Recommended):** Voice cloning models, especially advanced ones like XTTS, are computationally intensive. An NVIDIA GPU with CUDA correctly set up will provide significantly faster processing.
    *   **CPU:** The script can run on a CPU, but expect it to be much slower. Some models may have issues or be impractically slow on CPU. The script includes some error messages for common GPU/CUDA related issues.
*   **Voice Sample Quality:** The clarity and quality of your `SPEAKER_WAV_PATH` file will directly impact the quality of the cloned voice.
*   **Internet Connection:** A stable internet connection is needed for the initial model download.
*   **Python Environment & Dependencies:** Ensure `coqui-tts` and its dependencies (like PyTorch) are correctly installed in the Python environment you are using to run the script.
*   **Audio Playback Command:** The script includes basic OS detection to use appropriate playback commands (`start` for Windows, `afplay` for macOS, `aplay` or `xdg-open` for Linux). If playback doesn't work, you might need to install a command-line audio player (like `aplay` on Linux, often part of `alsa-utils`) or adjust the command in the script.
*   **Errors during Model Initialization:** If you see errors like "Error initializing TTS model," it could be due to an incorrect model name, issues downloading the model, or other configuration problems. The script suggests `print(TTS().list_models())` to see available models, which you can temporarily add to the script to debug.
*   **Errors during Synthesis:** Specific runtime errors can occur. The script tries to catch some common ones related to CUDA/GPU requirements for XTTS models.

This file should help you resume your work on F.R.E.D.'s TTS capabilities later. 