{
  "query": "Best practices and benchmarks (latency, accuracy, energy) for on-device multimodal RAG on Raspberry Pi 5 and smartphones in 2024-2025, including: STT+streaming VAD, WebRTC microphone streaming, low-latency TTS, incremental chunked retrieval, local vector DB options, CRDT/offline sync, and privacy trade-offs. Provide concrete numbers and recent studies.",
  "timestamp": "2025-08-06T00:01:24.352885",
  "results": {
    "query": "Best practices and benchmarks (latency, accuracy, energy) for on-device multimodal RAG on Raspberry Pi 5 and smartphones in 2024-2025, including: STT+streaming VAD, WebRTC microphone streaming, low-latency TTS, incremental chunked retrieval, local vector DB options, CRDT/offline sync, and privacy trade-offs. Provide concrete numbers and recent studies.",
    "links": [
      {
        "url": "https://developer.nvidia.com/blog/rag-101-retrieval-augmented-generation-questions-answered/",
        "title": "RAG 101: Retrieval-Augmented Generation Questions Answered | NVIDIA Technical Blog",
        "description": "Data scientists, AI engineers, MLOps engineers, and IT infrastructure professionals must consider a variety of factors when designing and deploying a <strong>RAG</strong> pipeline: from core components like LLM to…",
        "score": 0.6583127528724991
      },
      {
        "url": "https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation",
        "title": "Trends in Active Retrieval Augmented Generation: 2025 and Beyond",
        "description": "Discover how Active <strong>Retrieval</strong> Augmented Generation can transform your data insights and enhance decision-making. Read the article <strong>for</strong> <strong>practical</strong> strategies.",
        "score": 0.6130758393683249
      },
      {
        "url": "https://atsss.medium.com/real-time-speech-to-text-on-raspberry-pi-and-python-4be8c347a8fc",
        "title": "Real-time Speech-to-text on Raspberry Pi and Python | by Ats | Medium",
        "description": "Then I wanted to make scripts to do real-time speech-to-text for conversation between me <strong>and</strong> <strong>Raspberry</strong> <strong>Pi</strong>. Firstly, I set up my <strong>microphone</strong> <strong>on</strong> <strong>Raspberry</strong> <strong>Pi</strong>. I used the speaker hat and they <strong>provided</strong>…",
        "score": 0.6039591095930849
      },
      {
        "url": "https://webrtc.ventures/2025/04/optimizing-prompts-for-real-time-voice-ai/",
        "title": "Optimizing Prompts for Real-Time Voice AI – WebRTC.ventures",
        "description": "Voice AI is evolving, merging text-based prompt engineering with real-time audio/video needs. Optimized prompts and hybrid <strong>retrieval</strong> methods help build high-performance <strong>WebRTC</strong> solutions.",
        "score": 0.5902737144183643
      },
      {
        "url": "https://cartesia.ai/blog/state-of-voice-ai-2024",
        "title": "State of voice AI 2024 - Cartesia",
        "description": "Generate seamless speech, power voice applications, and fine-tune your own voice models on the fastest real-time AI platform.",
        "score": 0.4706260895863103
      }
    ],
    "extracted_content": [
      {
        "url": "https://developer.nvidia.com/blog/rag-101-retrieval-augmented-generation-questions-answered/",
        "title": "RAG 101: Retrieval-Augmented Generation Questions Answered | NVIDIA Technical Blog",
        "content": "Data scientists, AI engineers, MLOps engineers, and IT infrastructure professionals must consider a variety of factors when designing and deploying a RAG pipeline: from core components like LLM to evaluation approaches.\nThe key point is that RAG is a system, not just a model or set of models. This system consists of several stages, which were discussed at a high level in RAG 101: Demystifying Retrieval-Augmented Generation Pipelines. All these stages provide opportunities to make design decisions according to your needs.\nHere’s a list of top questions and answers.\nWhen should you fine-tune the LLM vs. using RAG?\nIn the world of LLMs, choosing between fine-tuning, Parameter-Efficient Fine-Tuning (PEFT), prompt engineering, and retrieval-augmented generation (RAG) depends on the specific needs and constraints of your application.\n- Fine-tuning customizes a pretrained LLM for a specific domain by updating most or all of its parameters with a domain-specific dataset. This approach is resource-intensive but yields high accuracy for specialized use cases.\n- PEFT modifies a pretrained LLM with fewer parameter updates, focusing on a subset of the model. It strikes a balance between accuracy and resource usage, offering improvements over prompt engineering with manageable data and computational demands.\n- Prompt engineering manipulates the input to an LLM to steer its output, without altering the model’s parameters. It’s the least resource-intensive method, suitable for applications with limited data and computational resources.\n- RAG enhances LLM prompts with information from external databases, effectively a sophisticated form of prompt engineering.\nIt’s not about using one technique or another. In fact, these techniques can be used in tandem. For example, PEFT might be integrated into a RAG system for further refinement of the LLM or embedding model. The best approach depends on the application’s specific requirements, balancing accuracy, resource availability, and computational constraints.\nFor more information about customization techniques that you can use to improve domain-specific accuracy, see Selecting Large Language Model Customization Techniques.\nWhen building an application with LLMs, start by implementing RAG to enhance the model’s responses with external information. This approach quickly improves relevance and depth.\nLater, model customization techniques as outlined earlier, can be employed if you need more domain-specific accuracy. This two-step process balances quick deployment with RAG and targeted improvements through model customization with efficient development and continuous enhancement strategies.\nHow to increase RAG accuracy without fine-tuning?\nThis question deserves not just its own post but several posts. In short, obtaining accuracy in enterprise solutions that leverage RAG is crucial, and fine-tuning is just one technique that may (or may not) improve accuracy in a RAG system.\nFirst and foremost, find a way to measure your RAG accuracy. If you don’t know where you’re beginning, you won’t know how to improve. There are several frameworks for evaluating RAG systems, such as Ragas, ARES, and Bench.\nAfter you have done some evaluation for accuracy, there are numerous places to look to improve the accuracy that does not require fine-tuning.\nAlthough it may sound trivial, first check to make sure that your data is being parsed and loaded correctly in the first place. For example, if documents contain tables or even images, certain data loaders may miss information in documents.\nAfter data is ingested, it is chunked. This is the process of splitting text into segments. A chunk can be a fixed character length, but there are various chunking methods, such as sentence splitting and recursive chunking. How text is chunked determines how it is stored in an embedding vector for retrieval.\nOn top of this, there are many indexing and associated retrieval patterns. For example, several indexes can be constructed for various kinds of user questions and a user query can be routed according to an LLM to the appropriate index.\nThere are also a variety of retrieval strategies. The most rudimentary strategy is using cosine similarity with an index, but BM25, custom retrievers, or knowledge graphs can also improve the retrieval.\nReranking of results from the retriever can also provide additional flexibility and accuracy improvements according to unique requirements. Query transformations can work well to break down more complex questions. Even just changing the LLM’s system prompt can drastically change accuracy.\nAt the end of the day, it’s important to take time to experiment and measure the changes in accuracy that various approaches provide.\nRemember, models like the LLM or embedding model are merely a part of a RAG system. There are many ways to improve RAG systems to achieve high accuracy without doing any fine-tuning.\nHow to connect LLMs to data sources?\nThere are a variety of frameworks for connecting LLMs to your data sources, such as LangChain and LlamaIndex. These frameworks provide a variety of features, like evaluation libraries, document loaders, and query methods. New solutions are also coming out all the time. We recommend reading about various frameworks and picking the software and components of the software that make the most sense for your application.\nCan RAG cite references for the data that it retrieves?\nYes. In fact, it improves the user experience if you can cite references for retrieved data. In the AI chatbot RAG workflow example found in the /NVIDIA/GenerativeAIExamples GitHub repo, we show how to link back to source documents.\nWhat type of data is needed for RAG? How to secure data?\nRight now, textual data is well supported for RAG. Support in RAG systems for other forms of data like images and tables is improving as more research into multi-modal use cases progresses. You may have to write additional tools for data preprocessing depending on your data and where it’s located. There are a variety of data loaders available from LlamaHub and LangChain. For more information about building enriched pipelines with chains, see Security LLM Systems Against Prompt Injection.\nSecuring data, particularly for an enterprise, is paramount. For example, some indexed data may be intended for only a particular set of users. Role-based access control (RBAC), which restricts access to a system depending on roles, can provide data access control. For example, a user session token can be used in the request to the vector database so that information that’s out of scope for that user’s permissions is not returned.\nA lot of the terms for securing a model in the environment are the same as you might use for securing a database or other critical asset. Think about how your system will log activities—the prompt inputs, outputs, and error results—that are the results of production pipelines. These may provide a rich set of data for product training and improvement, but also a source of data leaks like PII that must be carefully managed just as you are managing the model pipelines themselves.\nAI models have many common patterns to cloud deployments. You should take every advantage of tools like RBAC, rate limiting, and other controls common in those environments to make your AI deployments more robust. Models are just one element of these powerful pipelines. For more information, see Best Practices for Securing LLM Enabled Applications\nOne aspect important in any LLM deployment is the nature of interaction with your end users. So much of RAG pipelines are centered on the natural language inputs and outputs. Consider ways to ensure that the experience meets consistent expectations through input/output moderation.\nPeople can ask questions in many different ways. You can give your LLM a helping hand through tools like NeMo Guardrails, which can provide secondary checks on inputs and outputs to ensure that your system runs in tip-top shape, addresses questions it was built for, and helpfully guides users elsewhere for questions that the LLM application isn’t built to handle.\nHow to accelerate a RAG pipeline?\nRAG systems consist of many components, so there are ample opportunities to accelerate a RAG pipeline:\n- Data preprocessing\n- Indexing and retrieval\n- LLM inference\nData preprocessing\nDeduplication is the process of identifying and removing duplicate data. In the context of RAG data preprocessing, deduplication can be used to reduce the number of identical documents that must be indexed for retrieval.\nNVIDIA NeMo Data Curator uses NVIDIA GPUs to accelerate deduplication by performing min hashing, Jaccard similarity computing, and connected component analysis in parallel. This can significantly reduce the amount of time it takes to deduplicate a large dataset.\nAnother opportunity is chunking. Dividing a large text corpus into smaller, more manageable chunks must be done because the downstream embedding model can only encode sentences below the maximum length. Popular embedding models such as OpenAI can encode up to 1536 tokens. If the text has more tokens, it is simply truncated.\nNVIDIA cuDF can be used to accelerate chunking by performing parallel data frame operations on the GPU. This can significantly reduce the amount of time required to chunk a large corpus.\nLastly, you can accelerate a tokenizer on the GPU. Tokenizers are responsible for converting text into integers as tokens, which are then used by the embedding model. The process of tokenizing text can be computationally expensive, especially for large datasets.\nIndexing and retrieval\nThe generation of embeddings is frequently a recurring process since RAG is well-suited for knowledge bases that are frequently updated. Retrieval is done at inference time, so low latency is a requirement. These processes can be accelerated by NVIDIA NeMo Retriever. NeMo Retriever aims to provide state-of-the-art, commercially ready models and microservices, optimized for the lowest latency and highest throughput.\nLLM inference\nAt a minimum, an LLM is used for the generation of a fully formed response. LLMs can also be used for tasks such as query decomposition and routing.\nWith several calls to an LLM, low latency for the LLM is crucial. NVIDIA NeMo includes TensorRT-LLM for model deployment, which optimizes the LLM to achieve both ground-breaking inference acceleration and GPU efficiency.\nNVIDIA Triton Inference Server also enables the optimized LLM to be deployed for high-performance, cost-effective, and low-latency inference.\nWhat are solutions to improve latency for a chatbot?\nBeyond using the suggestions to accelerate your RAG pipeline like NeMo Retriever and NeMo inference container with Triton Inference Server and TensorRT-LLM, it is important to consider using streaming to improve the perceived latency of the chatbot. As responses can be long, a streaming UI displaying parts of the response as they become available can mitigate perceived latency.\nIt may be worthwhile to consider using a smaller LLM that is fine-tuned for your use case. In general, smaller LLMs have much lower latency than larger LLMs.\nSome fine-tuned 7B models have demonstrated out-performing the accuracy of GPT-4 on specific tasks, for example, SQL generation. For example, ChipNeMo, a custom LLM built for internal use at NVIDIA to help engineers generate and optimize software for chip design, uses a 13B fine-tuned model instead of a 70B-parameter model. TensorRT-LLM delivers model optimizations such as flashing, FlashAttention, PagedAttention, Distillation, and Quantization for running smaller fine-tuned models locally, which can be used to decrease the memory used by the LLM.\nLatency for LLM responses is a function of the time to first token (TTFT) and the time per output token (TPOT).\nBoth TTFT and TPOT will be lower for a smaller LLM.\nGet started building RAG in your enterprise\nBy using RAG, you can provide up-to-date and proprietary information with ease to LLMs and build a system that increases user trust, improves user experiences, and reduces hallucinations.\nExplore the NVIDIA AI chatbot RAG workflow to get started building a chatbot that can accurately answer domain-specific questions in natural language using up-to-date information.\nFor those building enterprise RAG applications, NVIDIA NeMo is an end-to-end platform for developing custom generative AI, anywhere. Deliver enterprise-ready models with precise data curation, cutting-edge customization, RAG, and accelerated performance.",
        "description": "Data scientists, AI engineers, MLOps engineers, and IT infrastructure professionals must consider a variety of factors when designing and deploying a RAG pipeline: from core components like LLM to…",
        "publish_date": "2023-12-18",
        "author": "Hayden Wolff"
      },
      {
        "url": "https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation",
        "title": "Trends in Active Retrieval Augmented Generation: 2025 and Beyond",
        "content": "Trends in Active Retrieval Augmented Generation: 2025 and Beyond\nRAG is advancing AI with real-time retrieval, hybrid search, and multimodal capabilities. Trends like personalized RAG, on-device AI, and scalable solutions will impact industries. This blog explores RAG’s future and its business potential in 2025 and beyond.\nRetrieval-Augmented Generation (RAG) is gaining traction due to its ability to enhance the accuracy and contextual understanding of AI-generated content. Businesses leveraging RAG benefit from improved efficiency optimization, enhanced data curation, and better compliance with regulatory requirements.\nBy integrating data management systems and robust data pipelines, organizations can refine their generative AI applications and retrieve relevant information from multiple data sources.\nretrieval augmented generation services optimize AI responses to user queries by retrieving relevant data based on the input query. From document search to AI-driven support, they enhance accuracy, relevance, and efficiency in content generation.\nHowever, implementing RAG comes with challenges.\nThe computational expense of running large-scale RAG models can be significant, particularly when dealing with real-time latency constraints. Ensuring sensitive data security is another crucial concern, as RAG systems interact with vast repositories of technical documentation, graph databases, and unstructured data.\nThis blog will help you explore the future trends in RAG, its integration, and RAG applications in various industries.\n- Real-time and Hybrid RAG: AI will retrieve the latest information dynamically using real-time feeds and hybrid search techniques, improving accuracy and relevance.\n- Multimodal and Personalized AI: RAG will evolve beyond text, integrating images, videos, and audio while delivering highly personalized content through advanced fine-tuning.\n- On-device and efficient Retrieval: AI models will process data locally for better privacy and reduced latency, while sparse retrieval techniques enhance speed and efficiency.\n- RAG’s industry Impact: From legal and healthcare to finance and e-commerce, RAG will power precise decision-making, automation, and improved AI-driven insights.\nFuture Trends and Innovations in RAG\nEmerging advances in Retrieval-Augmented Generation (RAG) are expected to improve AI's capacity to retrieve and produce precise, context-aware material. The future of AI-driven knowledge systems will be shaped by innovations such as hybrid search, multimodal RAG, and real-time retrieval.\n1. Real-Time RAG\nAI systems will be able to dynamically retrieve the most recent information by integrating real data feeds into RAG models. Real-time RAG will guarantee that generative AI solutions deliver precise and contextually appropriate material by establishing connections with external knowledge bases, websites, and structured data sources.\nCompanies will use this capability to improve customer involvement and make choices, particularly in sectors that need constant data updates.\n2. Hybrid Models\nThe retrieval process will be optimized by combining keyword search with sophisticated retrieval techniques like knowledge graphs and semantic search. By obtaining pertinent documents from many data sources, optimizing search results, and increasing response accuracy, hybrid models will improve AI applications.\nInformation retrieval systems that analyze large datasets efficiently and relevantly will find this method especially helpful.\n3. Multimodal Content\nFor a more comprehensive AI-driven experience, RAG will develop beyond text-based retrieval to include photos, videos, and audio. AI systems will be able to evaluate and retrieve data from a variety of external sources by utilizing vector databases and hybrid retrieval techniques. Tools like an AI Image Enhancer can play a vital role in refining visual data, making it more suitable for AI interpretation and user-facing applications.\nThe overall user search experience will be improved by this innovation, which will increase AI's capacity to adapt to different information forms.\n4. Personalized RAG Implementation\nAI models will be able to retrieve and produce highly personalized content thanks to developments in fine-tuning approaches like few-shot prompting and low-rank adaptation (LoRA). Customized RAG will improve customer interactions, obtain pertinent data based on context, and refine user questions.\nApplications such as AI-powered customer service, tailored suggestions, and adaptive learning systems will benefit greatly from these capabilities.\n5. On-Device AI\nMore RAG implementations will operate locally on user devices in response to the increasing desire for privacy and decentralized processing. By doing this, users will be able to process and retrieve data from their own data repositories, reducing their dependency on cloud-based retrieval techniques.\nBy enabling real-time information retrieval without external data access, on-device AI will also improve data security and reduce latency.\n6. Sparsity Techniques\nSparse retrieval models and effective data architecture will enhance the retrieval system, lowering processing costs and guaranteeing quicker search results. These methods will improve AI applications in large-scale sectors, including cybersecurity, healthcare, and finance, where quick information retrieval is essential.\n7. Active Retrieval-Augmented Generation\nGenerative AI models will use sophisticated retrieval techniques like semantic search, vector search, and graph embeddings to extract pertinent documents and outside information sources proactively. Artificial intelligence (AI) applications will provide increasingly accurate and contextually rich content by continuously improving their retrieval processes.\n8. RAG as a Service\nBusinesses will be able to deploy scalable, affordable RAG architectures thanks to cloud-based RAG solutions. Organizations may maximize their AI capabilities, expedite data access, and incorporate AI-powered retrieval systems into their workflows without having to make large infrastructure investments by implementing RAG as a Service.\n9. Advancements in RAG Architecture\nEnhancing information retrieval efficiency, integrating numerous data sources, and maximizing AI model performance will be the main goals of ongoing research and development in retrieval-augmented generation work. Businesses can produce AI-generated content that is more accurate and efficient by optimizing retrieval workflows and enhancing external knowledge integration.\n10. Enhanced RAG Pipeline\nFuture advancements will improve the way AI models pull pertinent data from external data sources in the retrieval mechanism. Better retrieval augmentation techniques can further streamline the retrieval process and guarantee that AI-generated answers are based on the most up-to-date and accurate data.\nRAG Applications in Various Industries\nRetrieval-augmented generation (RAG) is improving AI-driven knowledge retrieval and decision-making, revolutionizing a number of industries. Companies can deliver precise, up-to-date information in a variety of domains by leveraging RAG-powered insights.\n1. Legal Tech\nFaster legal research and precedent identification are made possible by AI-driven case law analysis, which helps attorneys present more compelling arguments. Inconsistencies and compliance hazards are found via automated contract review, which guarantees that documents adhere to legal requirements. AI-powered regulatory updates also assist law firms in keeping up with changing legal regulations.\n2. Healthcare\nAI-assisted clinical decision support helps physicians make well-informed decisions by retrieving the most recent medical guidelines. By examining past medical records and present medical problems, personalized treatment recommendations enhance patient care. Additionally, AI-powered medical billing and coding improves accuracy while lessening the administrative burden on healthcare practitioners.\n3. Finance\nReal-time financial risk prevention is achieved using AI-driven fraud detection, which finds transaction irregularities. Automated investing insights examine consumer preferences and market developments to provide tailored financial solutions. Additionally, regulatory compliance monitoring driven by AI guarantees that companies easily comply with evolving financial requirements.\nRelated read: Check out more about RAG in financial services\n4. Customer Service\nChatbots and virtual assistants driven by AI improve client engagement by responding with precision and personalization. Self-service assistance is improved by knowledge base automation, which provides rapid access to pertinent information. Businesses can have more successful and sympathetic relationships with customers by using sentiment analysis to further customer engagement and better understand their feelings.\n5. E-commerce & Retail\nAI-powered product suggestions use consumer behavior analysis to tailor shopping experiences. In order to maintain competitive positioning, dynamic pricing optimization modifies prices in response to market movements. AI-powered inventory forecasting also assists companies in maintaining ideal stock levels, avoiding shortages or surpluses.\n6. Education & E-learning\nAdaptive learning driven by AI improves learning results by customizing instructional materials to each student's needs. By including the most recent information, automated content curation ensures that course materials remain current. AI-powered real-time tutoring offers immediate assistance, enabling students to get help whenever they need it.\n7. Manufacturing and Supply Chain\nPredictive maintenance driven by AI stops equipment failures by seeing possible problems before they happen. By tracking shipments and forecasting demand, real-time supply chain monitoring improves logistics.\nDefect detection is guaranteed by AI-driven quality control analysis, increasing the overall dependability of the product.\nMust Read - 10 Real World Examples of Retrieval Augmented Generation\nIntegration of Retrieval-Augmented Generation (RAG)\nRAG is becoming a fundamental component in AI systems, improving how large language models (LLMs) interact with external knowledge sources. Innovations like real-time retrieval augmented generation and RAG-streaming will enable large language models with seamless data integration.\n1. Adaptive Retrieval\nTraditional search techniques' dependence on static retrieval procedures makes them ineffective for complicated queries. By dynamically adapting to query complexity, adaptive retrieval techniques improve search procedures and guarantee that AI systems return the most pertinent and superior material.\nAI-powered retrieval engines can increase the accuracy and efficiency of system searches by better understanding user intent through the use of semantic search, vector search, and hybrid search.\n2. Hybrid Search\nBy merging structured and unstructured data sources, hybrid search techniques will maximize data extraction. To improve retrieval operations, these techniques use graph embeddings, vector databases, and keyword-based search.\nHybrid search strategies guarantee thorough and accurate information retrieval in sectors like banking and healthcare, where AI models require access to both structured records and unstructured textual material.\n3. Knowledge Graphs and Graph Embeddings\nThe comprehension and retention of contextual information by AI applications will be improved via knowledge graphs and graph embeddings. These technologies will allow AI algorithms to obtain interconnected insights rather than discrete facts by mapping relationships between data pieces.\nIt will be especially helpful in enterprise knowledge management platforms, chatbots, and AI-driven decision-making systems where it's critical to preserve context over several interactions.\n4. Multimodal RAG for Enhanced AI Interactions\nBeyond text-based AI models, retrieval-augmented generation has a bright future. Multimodal RAG will include a variety of data formats, such as audio, video, and image, into AI-powered systems. By adding picture retrieval, speech-to-text conversion, and video analysis to their retrieval pipelines, AI assistants, chatbots, and content production models will be able to offer more comprehensive responses.\nAI-powered systems will provide more interesting and educational user experiences as companies embrace multimodal retrieval.\n5. Self-Querying RAG Models\nAI systems are developing the ability to refine their search queries on their own. In order to obtain more pertinent information, self-querying RAG models will automatically evaluate and reword search queries. These models will iteratively improve query precision, reduce noise, and improve output quality by utilizing low-rank adaptation (LoRA), context-aware prompting, and few-shot prompting.\nApplications such as AI-powered research assistants, customer service bots, and compliance monitoring systems would particularly benefit from this.\n6. RAG as a Service\nRAG in Edge Computing will be essential to enabling decentralized AI as worries over latency and data privacy increase. On-device artificial intelligence (AI) will improve real-time decision-making, lower fraud exposure, and lessen regulatory compliance concerns by processing data locally on devices rather than depending on cloud-based retrieval.\nIt will be especially important for sectors that handle sensitive data, like cybersecurity, healthcare, and finance, where data privacy is crucial.\nRAG Process and Mechanisms\nThe RAG pipeline consists of several critical stages, ensuring that AI can retrieve and generate accurate information efficiently:\n-\nDocument Processing: Data ingestion and structuring using dual-encoder architecture and knowledge bases.\n-\nQuery Processing: Transforming user queries into machine-readable formats via semantic search and keyword search.\n-\nRetrieval: Using vector search and knowledge graphs to extract relevant data from external data sources and training data.\n-\nContext Assembly: Integrating retrieved data into the generation process using advanced retrieval methods.\n-\nGeneration: Producing AI-driven responses with optimized RAG-token and RAG-sequence techniques, leveraging the latest AI technology.\nObservability and AI readiness will be essential in ensuring the smooth implementation of these processes. Proper access control mechanisms will also be crucial for safeguarding sensitive data and source documents.\nEnhance AI with Signity\nAt Signity, we help businesses stay ahead in the evolving landscape of Retrieval-Augmented Generation (RAG). Our expertise in real-time retrieval, multimodal RAG, and hybrid retrieval techniques ensures that your AI solutions are contextually aware and industry-specific.\nMaximize Business Efficiency With Active RAG\nExplore how AI-driven retrieval can enhance productivity, accuracy, and customer experience.\nBy seamlessly integrating RAG with external data sources, we enable you to leverage massive datasets for more accurate and relevant content generation.\nWith a focus on enhanced security, efficiency optimization, and cutting-edge AI advancements, Signity empowers organizations to gain a competitive edge with knowledge-driven AI solutions development. Let us help you unlock the full potential of RAG for your business.\nFrequently Asked Questions\nHave a question in mind? We are here to answer. If you don’t see your question here, drop us a line at our contact page.\nWhat is Retrieval-Augmented Generation (RAG), and how does it work?\nRAG is an AI framework that enhances generative models by retrieving relevant external data before generating responses. It improves contextual accuracy by integrating structured and unstructured data sources, ensuring AI-generated content remains precise and up-to-date.\nWhat are the key benefits of using RAG in AI applications?\nWhat challenges do businesses face when implementing RAG?\nWhat are the emerging trends in RAG technology for 2025 and beyond?\nHow can businesses effectively implement RAG in their AI workflows?",
        "description": "Discover how Active Retrieval Augmented Generation can transform your data insights and enhance decision-making. Read the article for practical strategies.",
        "publish_date": "2025-02-12",
        "author": "Sachin Kalotra"
      },
      {
        "url": "https://atsss.medium.com/real-time-speech-to-text-on-raspberry-pi-and-python-4be8c347a8fc",
        "title": "Real-time Speech-to-text on Raspberry Pi and Python",
        "content": "Real-time Speech-to-text on Raspberry Pi and Python\nThis is the document about what I did for the real-time STT on Raspberry Pi and Python.\nFirst of all\nThese are my development environments.\nHardware\n- Raspberry Pi CM4 Model B (RAM 2GB)\n- Waveshare Raspberry Pi CM4 IO board (https://www.waveshare.com/cm4-io-base-b.htm)\n- ReSpeaker 2-Mics Pi HAT (https://wiki.seeedstudio.com/ReSpeaker/)\nSoftware\n- Raspberry Pi OS Bullseys\nThe reason why I didn’t use the bookworm is because I couldn’t use it with ReSpeaker 2-Mics Pi HAT.\nBackground\nI made a small application to do local text-to-speech scripts before.\nThen I wanted to make scripts to do real-time speech-to-text for conversation between me and Raspberry Pi.\nWhat I did\nFirstly, I set up my microphone on Raspberry Pi. I used the speaker hat and they provided the setup script to install the driver. It was straightforward.\nSoftware-wise, I used pyaudio\nand I couldn't install it via pip\n. I checked the official document and it said I needed to install portaudio19-dev\nto install it. Then the setup was done.\nsudo apt-get install portaudio19-dev\nSecondly, I was looking for a way to do STT and trying to do that locally without sending requests to any service. Then I found the whisper package.\nMy Raspberry Pi has 2GB of RAM so the tiny\nand base\nmodels should work on it. This time, I chose the tiny\none because I prioritized the speed.\nBut the response speed was still slow. I didn’t measure properly but it took more than 5 seconds. It was critical for the real-time STT and I didn’t find other good options to do locally. So I decided to include the ways for STT with requests. Then the Google Speech-to-Text and OpentAI whisper came to my options.\nGoogle: https://cloud.google.com/speech-to-text\nOpenAI: https://platform.openai.com/docs/guides/speech-to-text\nThe STTs with requests were much faster than doing locally. They took around 1 second. In short sentences, it took less than 1 second but in long sentences, it took more than 1 second. Then I chose the Whisper because the accuracy was higher than Google’s result, especially for my Japanese English accent.\nLastly, I wanted to make the speed much faster but It seemed the best with current opened models. So I decided to focus on sending requests with short sentences. I needed to know the end of sentences while listening conversation to keep the sentence short. Then I found the following library.\nspeech_recognition\nbundles utility functions for speech. Also it supports OpenAI API and pyaudio\ninterface. Then I found the following function called listen\n, which can detect the end of speech.\nI decided to go with the function to keep the sentence short. I want to note one thing here, which is that I needed to call the adjust_for_ambient_noise\nfunction before calling thelisten\nfunction. Actually, it doesn’t show any errors even if you don’t call the adjust_for_ambient_noise\nfunction. But the listen\ndidn’t detect the end properly without it. Once I called the function, the listen\nfunction worked as I expected.\nMy final script is below. I used the concurrent\nthread to keep listening to the conversation while sending requests to OpenAI.\nimport os\nimport speech_recognition as sr\nfrom concurrent import futures\nAPI_KEY = 'your_api_key'\nclass SpeechRecognizer:\ndef __init__(self):\nos.makedirs(\"./out\", exist_ok=True)\nself.path = f\"./out/asr.txt\"\nself.rec = sr.Recognizer()\nself.mic = sr.Microphone()\nself.pool = futures.ThreadPoolExecutor(thread_name_prefix=\"Rec Thread\")\nself.speech = []\ndef recognize_audio_thread_pool(self, audio, event=None):\nfuture = self.pool.submit(self.recognize_audio, audio)\nself.speech.append(future)\ndef grab_audio(self) -> sr.AudioData:\nprint(\"Say something!\")\nwith self.mic as source:\naudio = self.rec.listen(source)\nreturn audio\ndef recognize_audio(self, audio: sr.AudioData) -> str:\nprint(\"Understanting!\")\ntry:\nspeech = self.rec.recognize_whisper_api(audio, model='whisper-1', api_key=API_KEY)\nexcept sr.UnknownValueError:\nspeech = \"# Failed to recognize speech\"\nprint(speech)\nexcept sr.RequestError as e:\nspeech = f\"# Invalid request:{e}\"\nprint(speech)\nreturn speech\ndef run(self):\nprint(\"Listening surrounding!\")\nwith self.mic as source:\nself.rec.adjust_for_ambient_noise(source, duration=5)\ntry:\nwhile True:\naudio = self.grab_audio()\nself.recognize_audio_thread_pool(audio)\nexcept KeyboardInterrupt:\nprint(\"Finished\")\nfinally:\nwith open(self.path, mode='w', encoding=\"utf-8\") as out:\nfutures.wait(self.speech)\nfor future in self.speech:\nprint(future.result())\nout.write(f\"{future.result()}\\n\")\nif __name__ == \"__main__\":\nsp = SpeechRecognizer()\nsp.run()\nThat’s it!",
        "description": "This is the document about what I did for the real-time STT on Raspberry Pi and Python.",
        "publish_date": "2024-05-26",
        "author": "Ats"
      }
    ],
    "summary": "[Published: Dec 2023] NVIDIA Technical Blog outlines key latency metrics (TTFT, TPOT) and optimization techniques like FlashAttention, PagedAttention, Distillation, and Quantization via TensorRT-LLM for reducing LLM inference latency and energy use; smaller fine-tuned models (7B–13B) show improved accuracy on specific tasks and better local deployment viability; chunking methods include fixed-length, sentence splitting, recursive; cuDF enables GPU-accelerated parallel chunking; NeMo Retriever supports low-latency retrieval; RBAC and session tokens used for access control in vector DBs; logging of prompts/outputs poses PII risks if unmanaged; no data on Raspberry Pi 5/smartphone benchmarks or real-time audio streaming, local vector DB performance, CRDT/offline sync, or privacy trade-offs.  \nNVIDIA Technical Blog | https://developer.nvidia.com/blog/rag-101-retrieval-augmented-generation-questions-answered/\n\n[Published: May 26, 2024] Real-time STT on Raspberry Pi CM4 using Whisper tiny model achieves >5 seconds latency; OpenAI Whisper API offers ~1 second response for short inputs but transmits audio to cloud; local processing enhances privacy but sacrifices speed; implemented with PyAudio and concurrent threading; no WebRTC integration, TTS, incremental retrieval, or local vector DBs used; system relies entirely on online APIs with no offline sync capability.  \nMedium | https://atsss.medium.com/real-time-speech-to-text-on-raspberry-pi-and-python-4be8c347a8fc\n\n[Published: Feb 12, 2025] On-device RAG is rising due to privacy and latency demands; hybrid search (keyword + semantic + graph) improves accuracy; multimodal RAG integrates audio/video/image via vector databases; sparse retrieval models reduce computational cost; real-time RAG uses live data feeds; self-querying RAG with LoRA/few-shot prompting enables query refinement; no concrete benchmarks for Raspberry Pi 5 or smartphones in 2024–2025; no metrics on STT+VAD, WebRTC streaming, low-latency TTS, incremental chunked retrieval, local vector DBs (FAISS/Chroma), CRDT/offline sync, or quantified privacy trade-offs.  \nSignity Solutions | https://www.signitysolutions.com/blog/trends-in-active-retrieval-augmented-generation",
    "search_priority": "quick",
    "mode": "auto"
  }
}